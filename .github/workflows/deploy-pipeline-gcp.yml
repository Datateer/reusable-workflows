# This will build an image from a prefect pipeline flow, push the image to the repository, and register the flow with prefect
# The image is built using an GCP GKE runner and docker storage is in GCP Cloud Storage

# this is a reusable workflow that should be used in every <client>-pipeline repository that needs to deploy to GCP
# refer to https://docs.github.com/en/actions/using-workflows/reusing-workflows

name: Deploy Pipeline
on:
  workflow_call:
    inputs:
      environment:
        description: The target environment to deploy to. prod, stg, qa, int, or a development environment
        required: true
        type: string
      pipeline_name:
        description: The name of the pipeline flow file e.g. for "pipeline_main.py," input "main"
        required: false
        type: string
        default: main
      gcpProjectId:
        description: The client's GCP project ID, e.g. prt-prod-1234566
        required: false # defaults to repo secret GCP_PROJECT_ID
        type: string
      gcpRegion:
        description: The client's GCP project region e.g. us-central1, us-east1, etc
        required: false # defaults to repo secret GCP_REGION
        type: string
      clientCode:
        description: The lowercase Datateer client code e.g. pkt, hmn, etc
        required: false # defaults to repo secret CLIENT_CODE
        type: string
      datateerCliVersion:
        description: Datateer CLI version. Leave blank to use the latest version. See https://pypi.org/project/datateer-cli/
        type: string
    secrets:
      deployKeyPrefectLib:
        description: The github deployment key that allows access to Datateer/datateer-prefect. This is available as an organization secret
        required: true
      deployKeyPrefect:
        description: The Prefect deployment key for this client's Prefect project
        required: true
      deployGoogleCredentials:
        description: The google service account credentials JSON used to authenticate with GCP
        required: true

jobs:
  deploy:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.8]
    name: Build and deploy the pipeline
    env:
      GCP_PROJECT_ID: ${{ inputs.gcpProjectId || secrets.GCP_PROJECT_ID }}
      GCP_REGION: ${{ inputs.gcpRegion || secrets.GCP_REGION }}
      CLIENT_CODE: ${{ inputs.clientCode || secrets.CLIENT_CODE }}
      DATATEER_ENV: ${{ inputs.environment || 'int' }}
      PIPELINE_NAME: ${{ inputs.pipeline_name || 'main' }}
    steps:
      - name: Prerequisites
        run: |
          [ -n "${{ env.GCP_PROJECT_ID }}" ] || (echo "Could not find GCP_PROJECT_ID in the inputs or in environment variables" && exit 1)
          [ -n "${{ env.GCP_REGION }}" ] || (echo "Could not find GCP_REGION in the inputs or in environment variables" && exit 1)
          [ -n "${{ env.CLIENT_CODE}}" ] || (echo "Could not find CLIENT_CODE in the inputs or in environment variables" && exit 1)
          [ -n "${{ env.DATATEER_ENV }}" ] || (echo "Could not find DATATEER_ENV in the inputs or in environment variables" && exit 1)

          python -m pip install --upgrade pip

          sudo apt-get install graphviz graphviz-dev
          if [ -n "${{ inputs.datateerCliVersion }}" ]
          then
            pip install datateer-cli==${{ inputs.datateerCliVersion }}
          else
            pip install datateer-cli
          fi

      # This has a serious limitation that makes it difficult to use beyond a single SSH key. Ref https://github.com/webfactory/ssh-agent#using-multiple-keys
      - name: Setup SSH
        uses: webfactory/ssh-agent@v0.4.1
        with:
          ssh-private-key: |
            ${{ secrets.deployKeyPrefectLib  }}

      - name: Checkout pipeline repo
        uses: actions/checkout@v3

      - uses: syphar/restore-pip-download-cache@v1
      - run: |
          chmod 755 ./.datateer/build_scripts/pre-build.sh
          ./.datateer/build_scripts/pre-build.sh
          pip install .

      - id: "auth"
        name: "Authenticate to Google Cloud"
        uses: "google-github-actions/auth@v0"
        with:
          token_format: "access_token"
          credentials_json: "${{ secrets.deployGoogleCredentials }}"

      - uses: "docker/login-action@v1"
        with:
          registry: "${{ env.GCP_REGION }}-docker.pkg.dev" # or REGION-docker.pkg.dev
          username: "oauth2accesstoken"
          password: "${{ steps.auth.outputs.access_token }}"

      - name: Pull down config settings files
        run: datateer config pull --environment ${{ env.DATATEER_ENV }} --cloud gcp --region ${{ env.GCP_REGION }} --config-bucket datateer-managed-${{ env.GCP_PROJECT_ID }}-prefect-config-data

      - name: Load docker layer cache
        uses: satackey/action-docker-layer-caching@v0.0.11
        # Ignore the failure of a step and avoid terminating the job.
        continue-on-error: true
        with:
          key: datateer-docker-pipeline-${{ env.CLIENT_CODE }}-${{ env.DATATEER_ENV }}-{hash}
          restore-keys: |
            datateer-docker-pipeline-${{ env.CLIENT_CODE }}-${{ env.DATATEER_ENV }}-
            datateer-docker-pipeline-${{ env.CLIENT_CODE }}-
            datateer-docker-pipeline-

      - name: Deploy pipeline
        run: datateer pipeline deploy ${{ env.PIPELINE_NAME }} --environment ${{ env.DATATEER_ENV }} --cloud gcp --region ${{ env.GCP_REGION }} --account ${{ env.GCP_PROJECT_ID }}
        env:
          DEPLOY_KEY_PREFECT_LIB: ${{ secrets.deployKeyPrefectLib }}
          PREFECT__CLOUD__API_KEY: ${{ secrets.deployKeyPrefect }}

      # TODO: get documentation deployment working again
#       - name: Deploy documentation
#         run: datateer docs deploy -c ${{ env.CLIENT_CODE }}
