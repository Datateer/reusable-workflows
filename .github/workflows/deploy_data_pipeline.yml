# this is a reusable workflow that should be used in every <client>-pipeline repository
# refer to https://docs.github.com/en/actions/using-workflows/reusing-workflows
name: Deploy Data Pipeline
on: 
  workflow_call:
    inputs:
      awsAccountId:
        description: The client's AWS account ID
        required: true
        type: string
      awsRegion:
        description: The client's AWS account region e.g. us-east-1, eu-west-2, etc
        required: true
        type: string
      clientCode:
        description: The lowercase Datateer client code e.g. pkt, hmn, etc
        required: true
        type: string
      datateerCliVersion:
        description: Datateer CLI version. See https://pypi.org/project/datateer-cli/
        default: v0.5.0
        type: string
    secrets:
      deployKeyDevopsLib:
        description: The github deployment key that allows access to Datateer/datateer-devops. This is available as an organization secret
        required: true
      deployKeyPrefectLib:
        description: The github deployment key that allows access to Datateer/datateer-prefect. This is available as an organization secret
        required: true
      deployKeyPrefect:
        description: The Prefect deployment key for this client's Prefect project
        required: true
      deploymentAgentAwsAccessKey:
        description: The AWS Access Key ID for the client's deployment agent. This should be stored as a repo secret in <client>-pipeline
        required: true
      deploymentAgentAwsAccessKeySecret: 
        description: The AWS Access Key Secret for the client's deployment agent. This should be stored as a repo secret in <client>-pipeline
        required: true

jobs:
  deploy_pipeline:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.8]
    name: Build and deploy the pipeline
    steps:
      - name: Set DATATEER_ENV (prod)
        if: github.ref == 'refs/heads/main'
        run: echo "DATATEER_ENV=prod" >> $GITHUB_ENV

      - name: Set DATATEER_ENV (staging)
        if: github.ref != 'refs/heads/main'
        run: echo "DATATEER_ENV=staging" >> $GITHUB_ENV

      - name: Load Env Vars from AWS Secrets Manager
        uses: say8425/aws-secrets-manager-actions@v2
        with:
          AWS_ACCESS_KEY_ID: ${{ secrets.deploymentAgentAwsAccessKey }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.deploymentAgentAwsAccessKeySecret }}
          AWS_DEFAULT_REGION: ${{ inputs.awsRegion }}
          SECRET_NAME: datateer-pipeline-settings-${{ env.DATATEER_ENV }}

      - name: Check if env variable is set after fetching secrets
        run: if [ -z $MELTANO_DATABASE_URI ]; then echo "MELTANO_DATABASE_URI is not set"; else echo "MELTANO_DATABASE_URI IS SET TO $MELTANO_DATABASE_URI"; fi

      - name: Setup python
        uses: actions/setup-python@v2
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install Graphviz
        run: sudo apt-get install graphviz graphviz-dev

      - name: Upgrade pip and setuptools
        run: pip install --upgrade pip setuptools

      - name: Checkout Datateer CLI
        uses: actions/checkout@v2
        with:
          repository: Datateer/datateer-devops
          ref: ${{ inputs.datateerCliVersion }}
          ssh-key: ${{ secrets.deployKeyDevopsLib }}
          path: datateer-devops

      - name: Install Datateer CLI
        run: pip install ./datateer-devops/

      # This has a serious limitation that makes it difficult to use beyond a single SSH key. Ref https://github.com/webfactory/ssh-agent#using-multiple-keys
      - name: Setup SSH
        uses: webfactory/ssh-agent@v0.4.1
        with:
          ssh-private-key: |
            ${{ secrets.deployKeyPrefectLib }}

      - name: Checkout pipeline
        uses: actions/checkout@v2

      - run: chmod 755 ./.datateer/build_scripts/pre-build.sh

      - run: ./.datateer/build_scripts/pre-build.sh

      - run: pip install .

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.deploymentAgentAwsAccessKey }}
          aws-secret-access-key: ${{ secrets.deploymentAgentAwsAccessKeySecret }}
          aws-region: ${{ inputs.awsRegion }}

      - name: Pull down config settings files
        run: datateer pipeline -e $DATATEER_ENV pull-config
        env:
          CLIENT_CODE: ${{ inputs.clientCode }}
        
      # The step that builds the docker image needs access to the meltano database. The next 2 steps dynamically open and close ports allowing github to access the AWS RDS database  
      - name: Get AWS security group ID for the meltano database
        id: security_group_id_step
        run: |
          VPC_ID=$(aws ec2 describe-vpcs --filters Name=tag:Name,Values=default --query "Vpcs[].VpcId" --output text)
          SECURITY_GROUP_ID=$(aws ec2 describe-security-groups --filter Name=vpc-id,Values=$VPC_ID Name=group-name,Values=meltano-db-sg --query 'SecurityGroups[*].[GroupId]' --output text)
          echo "::set-output name=security_group_id::$SECURITY_GROUP_ID"

      # If meltano is not in use, then then the security group ID will be empty and this step will not run
      - name: Add public IP to AWS security group so that meltano can deploy to the database
        if: ${{ null != steps.security_group_id_step.outputs.security_group_id  }}
        uses: sohelamin/aws-security-group-add-ip-action@master
        with:
          aws-access-key-id: ${{ secrets.deploymentAgentAwsAccessKey }}
          aws-secret-access-key: ${{ secrets.deploymentAgentAwsAccessKeySecret }}
          aws-region: ${{ inputs.awsRegion }}
          aws-security-group-id: ${{ steps.security_group_id_step.outputs.security_group_id }}
          port: '5432'
          to-port: '5432'
          protocol: 'tcp'
          description: 'Created by a GitHub Action - will be deleted when finished'

      - name: Load docker layer cache
        uses: satackey/action-docker-layer-caching@v0.0.11
        # Ignore the failure of a step and avoid terminating the job.
        continue-on-error: true
        with:
          key: datateer-docker-pipeline-${{ inputs.clientCode }}-${{ env.DATATEER_ENV }}-{hash}
          restore-keys: |
            datateer-docker-pipeline-${{ inputs.clientCode }}-${{ env.DATATEER_ENV }}-
            datateer-docker-pipeline-${{ inputs.clientCode }}-
            datateer-docker-pipeline-

      - name: Deploy pipeline
        run: datateer pipeline -e $DATATEER_ENV deploy
        env:
          AWS_ACCOUNT_ID: ${{ inputs.awsAccountId }}
          CLIENT_CODE: ${{ inputs.clientCode }}
          DATATEER_DEPLOY_KEY_PREFECT_LIB: ${{ secrets.deployKeyPrefectLib }}
          PREFECT__CLOUD__AUTH_TOKEN: ${{ secrets.deployKeyPrefect }}
          
      - name: Deploy documentation
        run: datateer docs deploy -c ${{ inputs.clientCode }}
